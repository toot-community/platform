serviceAccount: 
  create: true
  
server:
  retentionDiskSpaceUsage: "100"
  extraArgs:
    envflag.enable: true
    envflag.prefix: VM_
    loggerFormat: json
    httpListenAddr: :9428
    http.shutdownDelay: 15s
  
  persistentVolume:
    enabled: true
    size: 105Gi
    
  resources:
    requests:
      cpu: 45m
      memory: 1664Mi
    limits:
      memory: 1664Mi
      
  vmServiceScrape:
    enabled: true
    
vector:
  enabled: true
  resources:
    requests:
      cpu: 85m
      memory: 233Mi
    limits:
      memory: 1Gi # OOMKill if set to less than 1Gi

  # Additional volumes for Vector
  extraVolumes:
    - name: geoip-data
      persistentVolumeClaim:
        claimName: geoip-data
        readOnly: true

  extraVolumeMounts:
    - name: geoip-data
      mountPath: /geoip
      readOnly: true

  # Custom Vector configuration for ASN enrichment and metrics
  customConfig:
    data_dir: /vector-data-dir
    api:
      enabled: false
      address: 0.0.0.0:8686
      playground: false
            
    # Enrichment tables for GeoIP lookups
    enrichment_tables:
      geoip_asn:
        type: mmdb
        path: /geoip/GeoLite2-ASN.mmdb

    sources:
      k8s:
        type: kubernetes_logs
      internal_metrics:
        type: internal_metrics

    transforms:
      # Parse JSON logs
      parser:
        type: remap
        inputs:
          - k8s
        source: |
          .log = parse_json(.message) ?? .message
          del(.message)

      # Filter only Traefik access logs
      traefik_filter:
        type: filter
        inputs:
          - parser
        condition:
          type: vrl
          source: |
            exists(.log.ClientHost) &&
            exists(.log.ServiceName) &&
            exists(.log.RequestMethod)

      metrics_prep:
        type: remap
        inputs:
          - traefik_filter
        source: |
          # Perform GeoIP lookup using enrichment table (fallible, so use error assignment)
          geoip_data, err = get_enrichment_table_record("geoip_asn", { "ip": .log.ClientHost })
          if err != null {
            geoip_data = {}
          }

          # Extract ASN info (with fallbacks for unknown ASNs)
          asn_num_raw, _ = get(geoip_data, ["autonomous_system_number"])
          asn_org_raw, _ = get(geoip_data, ["autonomous_system_organization"])

          asn_num = int(asn_num_raw) ?? 0
          asn_organization = string(asn_org_raw) ?? "Unknown"

          .asn_number = to_string(asn_num)
          .asn_org = asn_organization

          # Truncate ASN org name to max 50 chars to control cardinality
          if length(.asn_org) > 50 {
            .asn_org = slice!(.asn_org, 0, 50)
          }

          # Extract service name from Traefik's ServiceName field
          # Example: "toot-community-varnish-for-app-http-80@kubernetesgateway"
          service_name = string(.log.ServiceName) ?? "unknown"
          # Remove the @kubernetesgateway suffix first
          service_name = string!(split(service_name, "@")[0])
          service_parts = split(service_name, "-")
          if length(service_parts) >= 3 {
            .service = join!(slice!(service_parts, 0, 3), "-")
          } else {
            .service = service_name
          }

          # Normalize status code to ranges to reduce cardinality
          status = to_int(.log.DownstreamStatus) ?? 0
          if status >= 200 && status < 300 {
            .status_class = "2xx"
          } else if status >= 300 && status < 400 {
            .status_class = "3xx"
          } else if status >= 400 && status < 500 {
            .status_class = "4xx"
          } else if status >= 500 {
            .status_class = "5xx"
          } else {
            .status_class = "other"
          }

          .bytes = to_int(.log.DownstreamContentSize) ?? 0
          .one = 1

      # Create metrics from enriched logs
      # Note: By default, log_to_metric uses current time for metric timestamps
      # (not the log event timestamp). This ensures accurate rate() calculations
      # in Prometheus/VictoriaMetrics by avoiding out-of-order samples.
      traefik_metrics:
        type: log_to_metric
        inputs:
          - metrics_prep
        metrics:
          # Counter: requests per ASN
          # Labels: asn_number, asn_org for identification
          #         service for namespace filtering (e.g., toot-community-varnish)
          #         status_class for error detection (2xx, 3xx, 4xx, 5xx)
          #         source_pod to prevent duplicate counting across Vector pods
          - type: counter
            field: one
            name: traefik_requests_by_asn_total
            namespace: traefik
            tags:
              asn_number: "{{`{{ asn_number }}`}}"
              asn_org: "{{`{{ asn_org }}`}}"
              service: "{{`{{ service }}`}}"
              status_class: "{{`{{ status_class }}`}}"
              source_pod: "{{`{{ kubernetes.pod_name }}`}}"

          # Counter: bytes transferred per ASN
          - type: counter
            field: bytes
            name: traefik_bytes_by_asn_total
            namespace: traefik
            tags:
              asn_number: "{{`{{ asn_number }}`}}"
              asn_org: "{{`{{ asn_org }}`}}"
              service: "{{`{{ service }}`}}"
              source_pod: "{{`{{ kubernetes.pod_name }}`}}"

      # Aggregate metrics before sending to VictoriaMetrics
      # This prevents sending individual metric events for each log line,
      # which causes rate() calculations to be inflated
      metrics_aggregator:
        type: aggregate
        inputs:
          - traefik_metrics
        interval_ms: 10000  # Flush every 10 seconds

    sinks:
      vlogs:
        type: elasticsearch
        inputs:
          - parser
        api_version: v8
        mode: bulk
        compression: gzip
        endpoints:
          - "http://vl-victoria-logs-single-server.victorialogs.svc.cluster.local:9428/insert/elasticsearch"
        request:
          headers:
            AccountID: "0"
            ProjectID: "0"
            VL-Msg-Field: "message,msg,_msg,log.msg,log.message,log"
            VL-Stream-Fields: "stream,kubernetes.pod_name,kubernetes.container_name,kubernetes.pod_namespace" # asn_number
            VL-Time-Field: "timestamp"
        healthcheck:
          enabled: true
          uri: "http://vl-victoria-logs-single-server.victorialogs.svc.cluster.local:9428/health"

      vmetrics:
        type: prometheus_remote_write
        inputs:
          - metrics_aggregator
        endpoint: "http://vmsingle-vm.victoriametrics.svc.cluster.local:8428/api/v1/write"
        batch:
          max_events: 1000
          timeout_secs: 1
        healthcheck:
          enabled: true
          uri: "http://vmsingle-vm.victoriametrics.svc.cluster.local:8428/health"

      exporter:
        type: prometheus_exporter
        inputs:
          - internal_metrics
        address: "0.0.0.0:9090"
  
dashboards:
  enabled: true
  labels:
    grafana_dashboard: "1"