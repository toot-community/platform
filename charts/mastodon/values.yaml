image:
  repository: ghcr.io/mastodon/mastodon
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}

podAnnotations: {}

podSecurityContext:
  fsGroup: 991
  runAsGroup: 991
  runAsUser: 991

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  runAsNonRoot: true
  runAsUser: 991

configuration:
  database:
    host: database-pooler-rw
    name: app
    poolsize: 25
    port: 5432
    dbMigrations: # to circumvent pgpooler
      port: 5432
      name: app
      host: database-rw
    sslmode: require
    runDatabaseMigrations: true
    credentials:
      usernameKey: username
      passwordKey: password
      secretName: database-app
  databaseReplicas:
    enabled: false
    host: database-pooler-ro
    port: 5432
  defaultLocale: en
  localDomain: example.com
  allowedPrivateAddresses: 10.0.0.0/8
  redis:
    host: haproxy-redis
    port: 6379
    database: 0
  s3:
    aliasHost: static.toot.community
    bucket: static-toot-community
    endpoint: https://endpoint.of.s3
    hostname: hostname.of.s3
    region: region
    protocol: https
    timeouts:
      open: 10
      read: 10
  smtp:
    authMethod: plain
    caFile: /etc/ssl/certs/ca-certificates.crt
    deliveryMethod: smtp
    enableStarttlsAuto: true
    opensslVerifyMode: peer
    port: 465
    domain: toot.community
    fromAddress: toot.community Notifications <notifications@toot.community>
    smtpServer: smtp.server
  search:
    enabled: true
    host: elasticsearch-es-http
    port: 9200
    scheme: http
    preset: single_node_cluster # https://github.com/mastodon/documentation/pull/1279/files
    user: elastic
    password:
      secretKeyRef:
        name: elasticsearch-es-elastic-user
        key: elastic
  ipRetentionPeriod: "31556952" # 1 year
  sessionRetentionPeriod: "31556952" # 1 year
  trustedProxyIPs: "10.0.0.0/16" # VPC CIDR

web:
  domain: toot.community
  concurrency: 2
  maxThreads: 5
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      memory: 4Gi # higher due to the need to convert big images using ImageMagick
  startupProbe:
    httpGet:
      port: http
      path: /health
    periodSeconds: 3
    failureThreshold: 30
  readinessProbe:
    failureThreshold: 3
    httpGet:
      path: /health
      port: http
      scheme: HTTP
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 10
  annotations: ~
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  podDisruptionBudget:
    enabled: true
    minAvailable: 2

translations:
  enabled: true
  libretranslate:
    endpoint: https://translate.mstdn.social/ # FIXME: set to deepl when their system works again
  # deepl:
    # plan: free

streaming:
  image:
    repository: ghcr.io/mastodon/mastodon-streaming
    pullPolicy: IfNotPresent
    tag: v4.3.8@sha256:9c258e83c69b7e6219425b1867e5851ffd53c9029e19e831bd31be8d80c5b42a
  replicaCount: 2
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  readinessProbe:
    failureThreshold: 3
    httpGet:
      path: /api/v1/streaming/health
      port: streaming
      scheme: HTTP
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 10
  startupProbe:
    httpGet:
      port: streaming
      path: /api/v1/streaming/health
    periodSeconds: 3
    failureThreshold: 30
  resources:
    requests:
      cpu: 6m
      memory: 202M
    limits:
      memory: 202M
  podDisruptionBudget:
    enabled: true
    minAvailable: 1
  podMonitor:
    enabled: false # FIXME: enable after observability is set up
    interval: 30s
    scrapeTimeout: 10s
    path: /metrics
    port: streaming
    scheme: http
  annotations: ~
  redis:
    url: redis://haproxy-redis:6379
  baseURL: wss://streaming.toot.community

sidekiq:
  workers:
    - name: generic
      concurrency: 25
      replicaCount: 1
      queues:
        - default
        - mailers
        - ingress
        - push
        - pull
      resources:
        requests:
          cpu: 500m
          memory: 1000M
        limits:
          memory: 1800M
    - name: scheduler
      concurrency: 25
      replicaCount: 1
      queues:
        - scheduler
      resources:
        requests:
          cpu: 100m
          memory: 300Mi
        limits:
          memory: 1800Mi

ingress:
  web:
    maxBodySize: 100m
    upstreamProxyTimeout: 120
    ingressClassName: nginx
    host: toot.community
    annotations: 
      cert-manager.io/cluster-issuer: letsencrypt
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    verifyClient:
      enabled: false
      secretName: tootcommunity/tootcommunity-ca-secret
    tls:
      - hosts:
          - toot.community
        secretName: toot.community-tls
  streaming:
    host: streaming.toot.community
    ingressClassName: nginx
    annotations: 
      cert-manager.io/cluster-issuer: letsencrypt
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    tls:
      - hosts:
          - streaming.toot.community
        secretName: streaming.toot.community-tls

jobs:
  annotations: ~
  cleanupMedia:
    enabled: true
    schedule: "0 5 * * *" # every day at 5am
    days: 7
    resources:
      requests:
        cpu: 250m
        memory: 750M
      limits:
        memory: 750M
  statusesRemove:
    enabled: true
    schedule: "5 4 * * 6"
    days: 90
    resources:
      requests:
        cpu: 300m
        memory: 1500M
      limits:
        memory: 1500M
  cleanupMediaProfiles:
    enabled: true
    schedule: "0 5 * * *" # every day at 5am
    days: 7
    resources:
      requests:
        cpu: 1000m
        memory: 721M
      limits:
        memory: 721M
  accountsPrune:
    enabled: true
    schedule: "0 2 * * 1" # every monday at 2am
    resources:
      requests:
        cpu: 1033m
        memory: 584M
      limits:
        memory: 584M
  removePreviewCards:
    enabled: true
    schedule: "0 5 * * 1" # every monday at 5am
    resources:
      requests:
        cpu: 500m
        memory: 400Mi
      limits:
        memory: 400Mi
    days: 180
  periodicWebRestart: # to circumvent memory leaks
    enabled: true
    schedule: "0 3,9,15,21 * * *"

s3Gateway:
  enabled: true
  image:
    repository: ghcr.io/nginx/nginx-s3-gateway/nginx-oss-s3-gateway
    pullPolicy: IfNotPresent
  replicaCount: 2
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  startupProbe: ~
    # httpGet:
    #   port: http
    #   path: /
    # periodSeconds: 3
    # failureThreshold: 30
  readinessProbe: ~
    # failureThreshold: 3
    # httpGet:
    #   path: /
    #   port: http
    #   scheme: HTTP
    # periodSeconds: 10
    # successThreshold: 1
    # timeoutSeconds: 10
  podSecurityContext:
    fsGroup: 101
    runAsGroup: 101
    runAsUser: 101
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    runAsNonRoot: true
    runAsUser: 101
  resources:
    requests:
      cpu: 100m
      memory: 200Mi
    limits:
      memory: 200Mi
  ingress:
    enabled: true
    ingressClassName: nginx
    host: static.example.com
    annotations: 
      cert-manager.io/cluster-issuer: letsencrypt
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    tls:
      - hosts:
          - static.example.com
        secretName: static-example.com-tls
    